input {
  kafka {
    bootstrap_servers => "kafka-broker1:9092,kafka-broker2:9092,kafka-broker3:9092"
    topics => ["search-logs"]
    group_id => "logstash-search-group"
    codec => "json"
    partition_assignment_strategy => "cooperative_sticky"

    consumer_threads => 3                      # 파티션 수만큼
    auto_offset_reset => "latest"
    auto_commit_interval_ms => "1000"
  }
}

filter {
  # timestamp → @timestamp
  date {
    match => ["timestamp", "ISO8601"]
    target => "@timestamp"
  }

  # Flatten nested Amadeus JSON fields to top-level
  mutate {
        add_field =>{
            "id" => "%[data][0][id]"
            "originLocationcode" => "%[data][0][itineraies]
        }
  }

  # 필드 리네이밍 및 타입 정제
  mutate {
    rename => { "origin" => "originLocationCode" }
    rename => { "destination" => "destinationLocationCode" }
    convert => { "id" => "Long" }
  }

  # 날짜 필드 파싱
  date {
    match => ["departureDate", "yyyy-MM-dd"]
    target => "departureDate"
  }
  date {
    match => ["returnDate", "yyyy-MM-dd"]
    target => "returnDate"
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "search-log"
    document_id => "%{id}"
  }

#  stdout {
#    codec => rubydebug
#  }
}